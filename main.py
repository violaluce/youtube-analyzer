import os
import json
import time
import requests
import re
import pandas as pd
import gspread
import urllib3
from bs4 import BeautifulSoup
from googleapiclient.discovery import build
from oauth2client.service_account import ServiceAccountCredentials
from datetime import datetime

# --- åˆæœŸè¨­å®š ---
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# GitHub Secretsã‹ã‚‰èª­ã¿è¾¼ã¿
YOUTUBE_API_KEY = os.environ.get('YOUTUBE_API_KEY')
GOOGLE_JSON_DATA = os.environ.get('GOOGLE_JSON_DATA')

def main():
    print("ğŸš€ å‡¦ç†é–‹å§‹...")
    
    # 1. ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰ã€Œãƒªãƒ¢ã‚³ãƒ³ï¼ˆB1ã‚»ãƒ«ï¼‰ã€ã®å€¤ã‚’èª­ã¿è¾¼ã‚€
    scope = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
    creds_dict = json.loads(GOOGLE_JSON_DATA)
    creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
    client = gspread.authorize(creds)
    
    # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆåã‚’ç¢ºèªï¼ˆã”è‡ªèº«ã®ã‚·ãƒ¼ãƒˆåã«åˆã‚ã›ã¦ãã ã•ã„ï¼‰
    spreadsheet_name = "YouTubeåˆ†æã‚·ãƒ¼ãƒˆ"
    sheet = client.open(spreadsheet_name).sheet1
    
    # B1ã‚»ãƒ«ã®æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—
    search_keyword = sheet.acell('B1').value
    if not search_keyword:
        print("B1ã‚»ãƒ«ã«æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚çµ‚äº†ã—ã¾ã™ã€‚")
        return
    print(f"ğŸ” æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {search_keyword}")

    # 2. ãƒ¦ãƒ¼ãƒãƒ¥ãƒ©ã§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼‰
    # æ¤œç´¢çµæœãƒšãƒ¼ã‚¸ã‚’ç›´æ¥å©ãå½¢ã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
    search_url = f"https://yutura.net/ranking/?q={search_keyword}"
    headers = {"User-Agent": "Mozilla/5.0"}
    res = requests.get(search_url, headers=headers, verify=False)
    soup = BeautifulSoup(res.text, 'html.parser')
    
    uc_ids = []
    print("ğŸ†” YouTube IDã‚’æŠ½å‡ºä¸­...")
    for a in soup.find_all('a'):
        href = a.get('href', '')
        if '/channel/' in href and 'channel' not in a.text:
            # è©³ç´°ãƒšãƒ¼ã‚¸ã‹ã‚‰UC-IDã‚’æŠœãå‡ºã™
            try:
                detail_res = requests.get("https://yutura.net" + href, headers=headers, verify=False)
                match = re.search(r'youtube\.com/channel/(UC[\w-]+)', detail_res.text)
                if match:
                    uc_ids.append(match.group(1))
                time.sleep(0.5) # è² è·è»½æ¸›
            except:
                continue
        if len(uc_ids) >= 15: break # ã¾ãšã¯ä¸Šä½15ä»¶

    # --- 3. YouTube APIã§è©³ç´°èª¿æŸ» ---
    if not uc_ids:
        print("âŒ YouTube IDãŒ1ã¤ã‚‚è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚B1ã‚»ãƒ«ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å¤‰ãˆã¦ã¿ã¦ãã ã•ã„ã€‚")
        return # IDãŒãªã„å ´åˆã¯ã“ã“ã§å®‰å…¨ã«çµ‚äº†ã•ã›ã‚‹

    print(f"ğŸ“Š 2. YouTube APIã§è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­ ({len(uc_ids)}ä»¶)...")
    youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)
    
    try:
        ch_res = youtube.channels().list(id=','.join(uc_ids), part='snippet,statistics').execute()
        
        # APIã®è¿”å´çµæœã« 'items' ãŒã‚ã‚‹ã‹ç¢ºèª
        if 'items' not in ch_res or not ch_res['items']:
            print("âš ï¸ APIã‹ã‚‰æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒè¿”ã£ã¦ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            return

        new_data = []
        for item in ch_res['items']:
            # ...ï¼ˆä»¥ä¸‹ã€ãƒ‡ãƒ¼ã‚¿ã®æ•´ç†ã¨æ›¸ãå‡ºã—å‡¦ç†ï¼‰
            stats = item['statistics']
            new_data.append({
            "æ—¥ä»˜": datetime.now().strftime('%Y-%m-%d'),
            "åå‰": item['snippet']['title'],
            "ç™»éŒ²è€…æ•°": int(stats.get('subscriberCount', 0)),
            "ç·å†ç”Ÿæ•°": int(stats.get('viewCount', 0)),
            "å‹•ç”»æ•°": int(stats.get('videoCount', 0)),
            "URL": f"https://www.youtube.com/channel/{item['id']}"
        })
    
    df_new = pd.DataFrame(new_data)

    # 4. ç•°å¤‰æ¤œçŸ¥ï¼ˆå‰å›ãƒ‡ãƒ¼ã‚¿ã¨ã®æ¯”è¼ƒï¼‰
    # å‰å›ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆ3è¡Œç›®ä»¥é™ã«æºœã¾ã£ã¦ã„ã‚‹ã¨ä»®å®šï¼‰ã‚’èª­ã¿è¾¼ã‚“ã§æ¯”è¼ƒã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯
    # ä»Šå›ã¯ã‚·ãƒ³ãƒ—ãƒ«ã«ã€æœ€æ–°ã®çµæœã‚’ã€ŒA3ã€ã‚»ãƒ«ã‹ã‚‰ä¸‹ã«æ›¸ãå‡ºã—ã¾ã™ã€‚
    # (B1ãŒå…¥åŠ›ã€A3ã‹ã‚‰çµæœè¡¨ã¨ã„ã†æ§‹æˆ)
    
    print("ğŸ“ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã¸æ›¸ãå‡ºã—ä¸­...")
    # ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚¹ãƒˆåŒ–
    output_list = [df_new.columns.values.tolist()] + df_new.values.tolist()
    
    # A3ã‚»ãƒ«ã‹ã‚‰çµæœã‚’ä¸Šæ›¸ã
    # sheet.update('A3', output_list) ã¯æœ€æ–°ã®gspreadã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«æ›¸ãã¾ã™
    sheet.update(range_name='A3', values=output_list)
    
    print(f"âœ… å®Œäº†ï¼'{search_keyword}' ã®èª¿æŸ»çµæœã‚’ã‚·ãƒ¼ãƒˆã«åæ˜ ã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    main()
